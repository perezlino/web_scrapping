{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5 - Encodings (Codificaciones)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Introducción**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cualquier documento HTML o XML está escrito en una codificación específica como `ASCII` o `UTF-8`. Pero cuando cargues ese documento en Beautiful Soup, descubrirás que ha sido convertido a Unicode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>SacrÃ© bleu!</h1>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "markup = \"<h1>Sacr\\xc3\\xa9 bleu!</h1>\"\n",
    "soup = BeautifulSoup(markup)\n",
    "soup.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SacrÃ© bleu!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.h1.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No es magia. Beautiful Soup utiliza una sub-librería llamada `Unicode, Dammit` para detectar la codificación de un documento y convertirlo a Unicode. La codificación autodetectada está disponible como atributo `.original_encoding` del objeto BeautifulSoup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.original_encoding  # 'utf-8'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Unicode, Dammit` adivina correctamente la mayoría de las veces, pero a veces se equivoca. A veces adivina correctamente, pero sólo después de una búsqueda byte a byte del documento que lleva mucho tiempo. Si conoces la codificación de un documento de antemano, puedes evitar errores y retrasos pasándosela al constructor de BeautifulSoup como from_encoding.\n",
    "\n",
    "Aquí hay un documento escrito en ISO-8859-8. El documento es tan corto que Unicode, Dammit no puede fijarse en él, y lo identifica erróneamente como ISO-8859-7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>翴檛</h1>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markup = b\"<h1>\\xed\\xe5\\xec\\xf9</h1>\"\n",
    "soup = BeautifulSoup(markup)\n",
    "soup.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Big5'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.original_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos solucionarlo introduciendo la codificación `from_encoding`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>םולש</h1>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(markup, from_encoding=\"iso-8859-8\")\n",
    "soup.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iso-8859-8'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.original_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no sabes cuál es la codificación correcta, pero sabes que `Unicode, Dammit` está adivinando mal, puedes pasar las conjeturas erróneas como `exclude_encodings`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>翴檛</h1>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(markup, exclude_encodings=[\"ISO-8859-7\"])\n",
    "soup.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Big5'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.original_encoding  # 'WINDOWS-1255'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Windows-1255 no es 100% correcto, pero esa codificación es un superconjunto compatible de ISO-8859-8, así que se acerca bastante. (exclude_encodings es una nueva función de Beautiful Soup 4.4.0.)\n",
    "\n",
    "En raras ocasiones (normalmente cuando un documento UTF-8 contiene texto escrito en una codificación completamente diferente), la única forma de obtener Unicode puede ser reemplazar algunos caracteres con el carácter especial Unicode \"REPLACEMENT CHARACTER\" (U+FFFD, �). Si Unicode, Dammit necesita hacer esto, establecerá el atributo `.contains_replacement_characters` a `True` en el objeto UnicodeDammit o BeautifulSoup. Esto le permite saber que la representación Unicode no es una representación exacta del original -algunos datos se perdieron. Si un documento contiene �, pero `.contains_replacement_characters` es `False`, sabrá que la � estaba ahí originalmente (como en este párrafo) y no sustituye a los datos que faltan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Codificación de salida**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando escribes un documento desde Beautiful Soup, obtienes un documento `UTF-8`, incluso si el documento no estaba en `UTF-8` al principio. Aquí hay un documento escrito en la codificación `Latin-1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-type\"/>\n",
      " </head>\n",
      " <body>\n",
      "  <p>\n",
      "   Sacré bleu!\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "markup = b'''\n",
    " <html>\n",
    "  <head>\n",
    "   <meta content=\"text/html; charset=ISO-Latin-1\" http-equiv=\"Content-type\" />\n",
    "  </head>\n",
    "  <body>\n",
    "   <p>Sacr\\xe9 bleu!</p>\n",
    "  </body>\n",
    " </html>\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(markup)\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta que la etiqueta `<meta>` se ha reescrito para reflejar el hecho de que el documento está ahora en `UTF-8`.\n",
    "\n",
    "Si no desea `UTF-8`, puede pasar una codificación a `prettify()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\n <head>\\n  <meta content=\"text/html; charset=latin-1\" http-equiv=\"Content-type\"/>\\n </head>\\n <body>\\n  <p>\\n   Sacr\\xe9 bleu!\\n  </p>\\n </body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify(\"latin-1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También puedes llamar a `encode()` sobre el objeto BeautifulSoup, o sobre cualquier elemento de soup, como si fuera una string de Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<p>Sacr\\xe9 bleu!</p>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.p.encode(\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<p>Sacr\\xc3\\xa9 bleu!</p>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.p.encode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los caracteres que no puedan representarse en la codificación elegida se convertirán en referencias numéricas a entidades XML. A continuación se muestra un documento que incluye el carácter Unicode SNOWMAN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "markup = u\"<b>\\N{SNOWMAN}</b>\"\n",
    "snowman_soup = BeautifulSoup(markup)\n",
    "tag = snowman_soup.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El carácter SNOWMAN puede formar parte de un documento UTF-8 (se parece a ☃), pero no existe representación para ese carácter en ISO-Latin-1 o ASCII, por lo que se convierte en \"&#9731\" para esas codificaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<b>\\xe2\\x98\\x83</b>'\n"
     ]
    }
   ],
   "source": [
    "print(tag.encode(\"utf-8\"))  # <b>☃</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<b>&#9731;</b>'\n"
     ]
    }
   ],
   "source": [
    "print (tag.encode(\"latin-1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<b>&#9731;</b>'\n"
     ]
    }
   ],
   "source": [
    "print (tag.encode(\"ascii\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Unicode, Dammit**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes usar `Unicode, Dammit` sin usar Beautiful Soup. Es útil cuando tienes datos en una codificación desconocida y sólo quieres que se conviertan en Unicode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SacrÃ© bleu!\n"
     ]
    }
   ],
   "source": [
    "from bs4 import UnicodeDammit\n",
    "\n",
    "dammit = UnicodeDammit(\"Sacr\\xc3\\xa9 bleu!\")\n",
    "print(dammit.unicode_markup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dammit.original_encoding  # 'utf-8'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las suposiciones de `Unicode, Dammit` serán mucho más precisas si instalas las bibliotecas `chardet` o `cchardet` de Python. Cuantos más datos le proporciones a `Unicode, Dammit`, más acertadas serán sus suposiciones. Si tienes tus propias sospechas sobre cuál podría ser la codificación, puedes pasarlas como una lista:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chardet\n",
      "  Obtaining dependency information for chardet from https://files.pythonhosted.org/packages/38/6f/f5fbc992a329ee4e0f288c1fe0e2ad9485ed064cac731ed2fe47dcc38cbf/chardet-5.2.0-py3-none-any.whl.metadata\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "   ---------------------------------------- 0.0/199.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/199.4 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/199.4 kB ? eta -:--:--\n",
      "   ------ -------------------------------- 30.7/199.4 kB 262.6 kB/s eta 0:00:01\n",
      "   -------- ------------------------------ 41.0/199.4 kB 281.8 kB/s eta 0:00:01\n",
      "   ------------ -------------------------- 61.4/199.4 kB 297.7 kB/s eta 0:00:01\n",
      "   ------------------------------- ------ 163.8/199.4 kB 701.4 kB/s eta 0:00:01\n",
      "   -------------------------------------- 199.4/199.4 kB 713.8 kB/s eta 0:00:00\n",
      "Installing collected packages: chardet\n",
      "Successfully installed chardet-5.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script chardetect.exe is installed in 'c:\\PySpark_Installed\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cchardet\n",
      "  Using cached cchardet-2.1.7.tar.gz (653 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: cchardet\n",
      "  Building wheel for cchardet (pyproject.toml): started\n",
      "  Building wheel for cchardet (pyproject.toml): finished with status 'error'\n",
      "Failed to build cchardet\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for cchardet (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [11 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\n",
      "      creating build\\lib.win-amd64-cpython-312\n",
      "      creating build\\lib.win-amd64-cpython-312\\cchardet\n",
      "      copying src\\cchardet\\version.py -> build\\lib.win-amd64-cpython-312\\cchardet\n",
      "      copying src\\cchardet\\__init__.py -> build\\lib.win-amd64-cpython-312\\cchardet\n",
      "      running build_ext\n",
      "      building 'cchardet._cchardet' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for cchardet\n",
      "ERROR: Could not build wheels for cchardet, which is required to install pyproject.toml-based projects\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install cchardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sacré bleu!\n"
     ]
    }
   ],
   "source": [
    "dammit = UnicodeDammit(\"Sacr\\xe9 bleu!\", \"latin-1\", \"iso-8859-1\")\n",
    "print(dammit.unicode_markup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dammit.original_encoding  # 'latin-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Codificaciones incoherentes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A veces un documento está mayoritariamente en UTF-8, pero contiene caracteres de Windows-1252 como (de nuevo) las smart quotes de Microsoft. Esto puede ocurrir cuando un sitio web incluye datos de múltiples fuentes. Puede utilizar `UnicodeDammit.detwingle()` para convertir un documento de este tipo en UTF-8 puro. He aquí un ejemplo sencillo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowmen = (u\"\\N{SNOWMAN}\" * 3)\n",
    "quote = (u\"\\N{LEFT DOUBLE QUOTATION MARK}I like snowmen!\\N{RIGHT DOUBLE QUOTATION MARK}\")\n",
    "doc = snowmen.encode(\"utf8\") + quote.encode(\"windows_1252\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este documento es un desastre. Los muñecos de nieve están en UTF-8 y las quotes en Windows-1252. Puedes mostrar los muñecos de nieve o las comillas (quotes), pero no ambos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xe2\\x98\\x83\\xe2\\x98\\x83\\xe2\\x98\\x83\\x93I like snowmen!\\x94'\n"
     ]
    }
   ],
   "source": [
    "print(doc)  # # ☃☃☃�I like snowmen!�"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â˜ƒâ˜ƒâ˜ƒ“I like snowmen!”\n"
     ]
    }
   ],
   "source": [
    "print(doc.decode(\"windows-1252\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decodificar el documento como UTF-8 genera un error UnicodeDecodeError, y decodificarlo como Windows-1252 te da un galimatías. Afortunadamente, `UnicodeDammit.detwingle()` convertirá el string a UTF-8 puro, permitiéndole decodificarlo a Unicode y mostrar los muñecos de nieve y las comillas simultáneamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "☃☃☃“I like snowmen!”\n"
     ]
    }
   ],
   "source": [
    "new_doc = UnicodeDammit.detwingle(doc)\n",
    "print(new_doc.decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`UnicodeDammit.detwingle()` sólo sabe cómo manejar Windows-1252 incrustado en UTF-8 (o viceversa, supongo), pero este es el caso más común.\n",
    "\n",
    "Tenga en cuenta que debe saber llamar a `UnicodeDammit.detwingle()` en sus datos antes de pasarlos a BeautifulSoup o al constructor UnicodeDammit. Beautiful Soup asume que un documento tiene una única codificación, sea cual sea. Si le pasas un documento que contiene tanto UTF-8 como Windows-1252, es probable que piense que todo el documento es Windows-1252, y el documento saldrá con un aspecto como el de â˜ƒâ˜ƒâ˜ƒ“I like snowmen!”."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

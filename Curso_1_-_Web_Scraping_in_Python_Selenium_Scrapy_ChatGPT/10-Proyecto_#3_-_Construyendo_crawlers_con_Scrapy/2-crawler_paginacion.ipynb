{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Crawler - Paginación**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a trabajar con el enlace:\n",
    "\n",
    "https://subslikescript.com/movies_letter-X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.postimg.cc/Pxb7C2Pg/ws-152.png\"></center>\n",
    "\n",
    "Buscamos el boton de la paginacion superior de \"**`pagina siguiente`**\" (existe un segundo boton que se encuntra en la paginacion inferior):\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/Y0psYYFh/ws-153.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La razón por la que puedo eliminar el \"**`callback`**\" en esta segunda regla es porque ya enviamos el callback igual a \"**`parse_item`**\" en el objeto de la primera regla. Así que cuando visitemos cada página siguiente, el \"parse_item\" será llamado por lo que no hay necesidad de codificar de nuevo en la segunda regla. Por otro lado, podemos omitir el argumento \"**`follow`**\" porque no estamos especificando el argumento \"**`callback`**\", así que si no hay argumento \"callback\" no hay necesidad del argumento \"**`follow`**\". Otra cosa que necesitas saber es que el orden en las reglas importa. Así que si la segunda regla estuviese en la primera posición, no scrapearemos la primera página."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto scrapearemos **`TODAS LAS PÁGINAS`** de las peliculas que comiencen con X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.linkextractors import LinkExtractor\n",
    "from scrapy.spiders import CrawlSpider, Rule\n",
    "\n",
    "\n",
    "class TranscriptsSpider(CrawlSpider):\n",
    "    name = 'transcripts'\n",
    "    allowed_domains = ['subslikescript.com']\n",
    "    start_urls = ['https://subslikescript.com/movies_letter-X']  # vamos a probar scrapeando todas las páginas para la letra X\n",
    "\n",
    "    # Establecer reglas para el crawler\n",
    "    rules = (\n",
    "        Rule(LinkExtractor(restrict_xpaths=(\"//ul[@class='scripts-list']/a\")), callback='parse_item', follow=True),\n",
    "        Rule(LinkExtractor(restrict_xpaths=(\"(//a[@rel='next'])[1]\"))),\n",
    "    )\n",
    "\n",
    "    def parse_item(self, response):\n",
    "        # Obtener la caja del article que contiene los datos que queremos (title, plot, etc)\n",
    "        article = response.xpath(\"//article[@class='main-article']\")\n",
    "\n",
    "        # Extraer los datos que queremos y luego devolverlos\n",
    "        yield {\n",
    "            'title':article.xpath(\"./h1/text()\").get(),\n",
    "            'plot':article.xpath(\"./p/text()\").get(),\n",
    "            # 'transcript':article.xpath(\"./div[@class='full-script']/text()\").getall(),\n",
    "            'url':response.url,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ejecutamos en el terminal:\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/8k7DCrGt/ws-154.png\"></center>\n",
    "\n",
    "Nos devuelve:\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/tCPj3QY6/ws-155.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, si queremos extraerlo en un archivo **`JSON`**:\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/9Xs2wFFV/ws-156.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/Qd3rS4Ty/ws-157.png\"></center>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
